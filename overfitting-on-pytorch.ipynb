{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:37.850185Z",
     "iopub.status.busy": "2021-03-16T12:56:37.849258Z",
     "iopub.status.idle": "2021-03-16T12:56:39.069916Z",
     "shell.execute_reply": "2021-03-16T12:56:39.069191Z"
    },
    "papermill": {
     "duration": 1.240116,
     "end_time": "2021-03-16T12:56:39.070153",
     "exception": false,
     "start_time": "2021-03-16T12:56:37.830037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n",
      "/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n",
      "/kaggle/input/fashionmnist/fashion-mnist_test.csv\n",
      "/kaggle/input/fashionmnist/fashion-mnist_train.csv\n",
      "/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n",
      "/kaggle/input/fashionmnist/train-images-idx3-ubyte\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:39.099360Z",
     "iopub.status.busy": "2021-03-16T12:56:39.098397Z",
     "iopub.status.idle": "2021-03-16T12:56:47.378294Z",
     "shell.execute_reply": "2021-03-16T12:56:47.377635Z"
    },
    "papermill": {
     "duration": 8.296267,
     "end_time": "2021-03-16T12:56:47.378522",
     "exception": false,
     "start_time": "2021-03-16T12:56:39.082255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:47.405820Z",
     "iopub.status.busy": "2021-03-16T12:56:47.404764Z",
     "iopub.status.idle": "2021-03-16T12:56:47.413740Z",
     "shell.execute_reply": "2021-03-16T12:56:47.413000Z"
    },
    "papermill": {
     "duration": 0.023671,
     "end_time": "2021-03-16T12:56:47.413894",
     "exception": false,
     "start_time": "2021-03-16T12:56:47.390223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: images(60000, 784), labels(60000, 1)\n",
      "Shape of test data: images(10000, 784), labels(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separating labels and samples\n",
    "x_train, y_train = train_data.iloc[:, 1:], train_data.iloc[:, :1]\n",
    "x_test, y_test = test_data.iloc[:, 1:], test_data.iloc[:, :1]\n",
    "print(f'Shape of train data: images{x_train.shape}, labels{y_train.shape}')\n",
    "print(f'Shape of test data: images{x_test.shape}, labels{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:47.442890Z",
     "iopub.status.busy": "2021-03-16T12:56:47.442134Z",
     "iopub.status.idle": "2021-03-16T12:56:47.567861Z",
     "shell.execute_reply": "2021-03-16T12:56:47.567092Z"
    },
    "papermill": {
     "duration": 0.142518,
     "end_time": "2021-03-16T12:56:47.568014",
     "exception": false,
     "start_time": "2021-03-16T12:56:47.425496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "x_train, x_test = x_train/255, x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:47.722364Z",
     "iopub.status.busy": "2021-03-16T12:56:47.721624Z",
     "iopub.status.idle": "2021-03-16T12:56:51.035725Z",
     "shell.execute_reply": "2021-03-16T12:56:51.036285Z"
    },
    "papermill": {
     "duration": 3.456635,
     "end_time": "2021-03-16T12:56:51.036494",
     "exception": false,
     "start_time": "2021-03-16T12:56:47.579859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>0.056819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135786</td>\n",
       "      <td>0.091375</td>\n",
       "      <td>0.065052</td>\n",
       "      <td>0.070076</td>\n",
       "      <td>0.089470</td>\n",
       "      <td>0.070241</td>\n",
       "      <td>0.033414</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.016890</td>\n",
       "      <td>0.022887</td>\n",
       "      <td>0.032216</td>\n",
       "      <td>0.055268</td>\n",
       "      <td>0.093410</td>\n",
       "      <td>0.150332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225668</td>\n",
       "      <td>0.191586</td>\n",
       "      <td>0.164626</td>\n",
       "      <td>0.172416</td>\n",
       "      <td>0.203257</td>\n",
       "      <td>0.177056</td>\n",
       "      <td>0.116137</td>\n",
       "      <td>0.068226</td>\n",
       "      <td>0.036694</td>\n",
       "      <td>0.008337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.886275</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pixel1        pixel2        pixel3        pixel4        pixel5  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.000004      0.000024      0.000139      0.000400      0.000972   \n",
       "std        0.000371      0.001063      0.004793      0.009619      0.016890   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.062745      0.141176      0.886275      0.643137      0.890196   \n",
       "\n",
       "             pixel6        pixel7        pixel8        pixel9       pixel10  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.001614      0.003160      0.008621      0.022282      0.056819   \n",
       "std        0.022887      0.032216      0.055268      0.093410      0.150332   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.901961      0.878431      1.000000      0.996078      1.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...      0.135786      0.091375      0.065052      0.070076   \n",
       "std    ...      0.225668      0.191586      0.164626      0.172416   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.227451      0.035294      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.089470      0.070241      0.033414      0.010797      0.003355   \n",
       "std        0.203257      0.177056      0.116137      0.068226      0.036694   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           pixel784  \n",
       "count  60000.000000  \n",
       "mean       0.000275  \n",
       "std        0.008337  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        0.666667  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.076518Z",
     "iopub.status.busy": "2021-03-16T12:56:51.075827Z",
     "iopub.status.idle": "2021-03-16T12:56:51.190387Z",
     "shell.execute_reply": "2021-03-16T12:56:51.189242Z"
    },
    "papermill": {
     "duration": 0.141346,
     "end_time": "2021-03-16T12:56:51.190547",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.049201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convertation to tensor\n",
    "train_x_tensor = torch.Tensor(x_train.values)\n",
    "train_y_tensor = torch.Tensor(y_train.values).type(torch.LongTensor)\n",
    "test_x_tensor = torch.Tensor(x_test.values)\n",
    "test_y_tensor = torch.Tensor(y_test.values).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.222118Z",
     "iopub.status.busy": "2021-03-16T12:56:51.221099Z",
     "iopub.status.idle": "2021-03-16T12:56:51.223631Z",
     "shell.execute_reply": "2021-03-16T12:56:51.224055Z"
    },
    "papermill": {
     "duration": 0.020823,
     "end_time": "2021-03-16T12:56:51.224240",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.203417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make tensor datasets\n",
    "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
    "test_dataset = TensorDataset(test_x_tensor, test_y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.254393Z",
     "iopub.status.busy": "2021-03-16T12:56:51.253417Z",
     "iopub.status.idle": "2021-03-16T12:56:51.285499Z",
     "shell.execute_reply": "2021-03-16T12:56:51.284672Z"
    },
    "papermill": {
     "duration": 0.048512,
     "end_time": "2021-03-16T12:56:51.285650",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.237138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X :  torch.Size([64, 784]) torch.float32\n",
      "Shape of y:  torch.Size([64, 1]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X : \", X.shape, X.dtype)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.318538Z",
     "iopub.status.busy": "2021-03-16T12:56:51.317574Z",
     "iopub.status.idle": "2021-03-16T12:56:51.322529Z",
     "shell.execute_reply": "2021-03-16T12:56:51.321950Z"
    },
    "papermill": {
     "duration": 0.023664,
     "end_time": "2021-03-16T12:56:51.322685",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.299021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.361469Z",
     "iopub.status.busy": "2021-03-16T12:56:51.360363Z",
     "iopub.status.idle": "2021-03-16T12:56:51.363711Z",
     "shell.execute_reply": "2021-03-16T12:56:51.364169Z"
    },
    "papermill": {
     "duration": 0.027647,
     "end_time": "2021-03-16T12:56:51.364370",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.336723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating Models\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, batchnorm=False, dropout=False, lr=1e-4, l2=0.):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, X, y, **kwargs):\n",
    "        self._loss = F.nll_loss(X, y, **kwargs)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.398072Z",
     "iopub.status.busy": "2021-03-16T12:56:51.397019Z",
     "iopub.status.idle": "2021-03-16T12:56:51.408774Z",
     "shell.execute_reply": "2021-03-16T12:56:51.408141Z"
    },
    "papermill": {
     "duration": 0.030458,
     "end_time": "2021-03-16T12:56:51.408917",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.378459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.442994Z",
     "iopub.status.busy": "2021-03-16T12:56:51.442285Z",
     "iopub.status.idle": "2021-03-16T12:56:51.446577Z",
     "shell.execute_reply": "2021-03-16T12:56:51.445831Z"
    },
    "papermill": {
     "duration": 0.02348,
     "end_time": "2021-03-16T12:56:51.446741",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.423261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_logs = []\n",
    "test_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.487286Z",
     "iopub.status.busy": "2021-03-16T12:56:51.486607Z",
     "iopub.status.idle": "2021-03-16T12:56:51.489080Z",
     "shell.execute_reply": "2021-03-16T12:56:51.489575Z"
    },
    "papermill": {
     "duration": 0.027232,
     "end_time": "2021-03-16T12:56:51.489776",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.462544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model):\n",
    "    model.train()\n",
    "    train_size = len(dataloader.dataset)\n",
    "    train_correct = 0.\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y = y.view(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        #train\n",
    "        pred = model(X)\n",
    "        train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        loss = model.loss(pred, y)\n",
    "        #Backpropagation\n",
    "        model.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        model.optim.step()\n",
    "            \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{train_size:>5d}]\")\n",
    "            \n",
    "    train_correct /= train_size\n",
    "    train_logs.append(train_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.535176Z",
     "iopub.status.busy": "2021-03-16T12:56:51.534198Z",
     "iopub.status.idle": "2021-03-16T12:56:51.538412Z",
     "shell.execute_reply": "2021-03-16T12:56:51.540069Z"
    },
    "papermill": {
     "duration": 0.035526,
     "end_time": "2021-03-16T12:56:51.540421",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.504895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    model.eval()\n",
    "    test_size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0., 0.\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y = y.view(-1)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += model.loss(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= test_size\n",
    "    correct /= test_size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    test_logs.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T12:56:51.581201Z",
     "iopub.status.busy": "2021-03-16T12:56:51.580175Z",
     "iopub.status.idle": "2021-03-16T13:02:36.512571Z",
     "shell.execute_reply": "2021-03-16T13:02:36.511504Z"
    },
    "papermill": {
     "duration": 344.952328,
     "end_time": "2021-03-16T13:02:36.512799",
     "exception": false,
     "start_time": "2021-03-16T12:56:51.560471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.286895  [    0/60000]\n",
      "loss: 1.492557  [ 6400/60000]\n",
      "loss: 1.059658  [12800/60000]\n",
      "loss: 0.847986  [19200/60000]\n",
      "loss: 0.779580  [25600/60000]\n",
      "loss: 0.747846  [32000/60000]\n",
      "loss: 0.625693  [38400/60000]\n",
      "loss: 0.466233  [44800/60000]\n",
      "loss: 0.450634  [51200/60000]\n",
      "loss: 0.545554  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.008788 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.623232  [    0/60000]\n",
      "loss: 0.541669  [ 6400/60000]\n",
      "loss: 0.623834  [12800/60000]\n",
      "loss: 0.542077  [19200/60000]\n",
      "loss: 0.434814  [25600/60000]\n",
      "loss: 0.454999  [32000/60000]\n",
      "loss: 0.458384  [38400/60000]\n",
      "loss: 0.318394  [44800/60000]\n",
      "loss: 0.340657  [51200/60000]\n",
      "loss: 0.415437  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.007175 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.518051  [    0/60000]\n",
      "loss: 0.471006  [ 6400/60000]\n",
      "loss: 0.581626  [12800/60000]\n",
      "loss: 0.471476  [19200/60000]\n",
      "loss: 0.362198  [25600/60000]\n",
      "loss: 0.391661  [32000/60000]\n",
      "loss: 0.430798  [38400/60000]\n",
      "loss: 0.289331  [44800/60000]\n",
      "loss: 0.311257  [51200/60000]\n",
      "loss: 0.363087  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.006600 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.480197  [    0/60000]\n",
      "loss: 0.442392  [ 6400/60000]\n",
      "loss: 0.554422  [12800/60000]\n",
      "loss: 0.440493  [19200/60000]\n",
      "loss: 0.324529  [25600/60000]\n",
      "loss: 0.357676  [32000/60000]\n",
      "loss: 0.419026  [38400/60000]\n",
      "loss: 0.273269  [44800/60000]\n",
      "loss: 0.297478  [51200/60000]\n",
      "loss: 0.333596  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006282 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.457780  [    0/60000]\n",
      "loss: 0.420169  [ 6400/60000]\n",
      "loss: 0.535605  [12800/60000]\n",
      "loss: 0.419118  [19200/60000]\n",
      "loss: 0.299642  [25600/60000]\n",
      "loss: 0.334610  [32000/60000]\n",
      "loss: 0.410109  [38400/60000]\n",
      "loss: 0.261433  [44800/60000]\n",
      "loss: 0.288691  [51200/60000]\n",
      "loss: 0.313830  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.006066 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.442778  [    0/60000]\n",
      "loss: 0.403073  [ 6400/60000]\n",
      "loss: 0.522391  [12800/60000]\n",
      "loss: 0.401740  [19200/60000]\n",
      "loss: 0.282696  [25600/60000]\n",
      "loss: 0.317306  [32000/60000]\n",
      "loss: 0.401771  [38400/60000]\n",
      "loss: 0.252974  [44800/60000]\n",
      "loss: 0.282136  [51200/60000]\n",
      "loss: 0.299095  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.005905 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.431662  [    0/60000]\n",
      "loss: 0.389954  [ 6400/60000]\n",
      "loss: 0.512500  [12800/60000]\n",
      "loss: 0.387141  [19200/60000]\n",
      "loss: 0.270091  [25600/60000]\n",
      "loss: 0.303114  [32000/60000]\n",
      "loss: 0.393501  [38400/60000]\n",
      "loss: 0.246967  [44800/60000]\n",
      "loss: 0.277003  [51200/60000]\n",
      "loss: 0.287285  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.005777 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.422826  [    0/60000]\n",
      "loss: 0.379659  [ 6400/60000]\n",
      "loss: 0.504540  [12800/60000]\n",
      "loss: 0.374769  [19200/60000]\n",
      "loss: 0.259967  [25600/60000]\n",
      "loss: 0.290791  [32000/60000]\n",
      "loss: 0.385216  [38400/60000]\n",
      "loss: 0.242542  [44800/60000]\n",
      "loss: 0.272863  [51200/60000]\n",
      "loss: 0.277113  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.005673 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.415491  [    0/60000]\n",
      "loss: 0.371482  [ 6400/60000]\n",
      "loss: 0.497871  [12800/60000]\n",
      "loss: 0.364097  [19200/60000]\n",
      "loss: 0.251524  [25600/60000]\n",
      "loss: 0.279921  [32000/60000]\n",
      "loss: 0.377017  [38400/60000]\n",
      "loss: 0.239098  [44800/60000]\n",
      "loss: 0.269337  [51200/60000]\n",
      "loss: 0.267781  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.005585 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.409215  [    0/60000]\n",
      "loss: 0.364951  [ 6400/60000]\n",
      "loss: 0.492274  [12800/60000]\n",
      "loss: 0.354770  [19200/60000]\n",
      "loss: 0.244375  [25600/60000]\n",
      "loss: 0.270295  [32000/60000]\n",
      "loss: 0.369042  [38400/60000]\n",
      "loss: 0.236282  [44800/60000]\n",
      "loss: 0.266106  [51200/60000]\n",
      "loss: 0.258911  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.005510 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.403715  [    0/60000]\n",
      "loss: 0.359655  [ 6400/60000]\n",
      "loss: 0.487544  [12800/60000]\n",
      "loss: 0.346577  [19200/60000]\n",
      "loss: 0.238297  [25600/60000]\n",
      "loss: 0.261736  [32000/60000]\n",
      "loss: 0.361417  [38400/60000]\n",
      "loss: 0.233870  [44800/60000]\n",
      "loss: 0.262969  [51200/60000]\n",
      "loss: 0.250404  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.005445 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.398821  [    0/60000]\n",
      "loss: 0.355214  [ 6400/60000]\n",
      "loss: 0.483420  [12800/60000]\n",
      "loss: 0.339319  [19200/60000]\n",
      "loss: 0.233124  [25600/60000]\n",
      "loss: 0.254151  [32000/60000]\n",
      "loss: 0.354216  [38400/60000]\n",
      "loss: 0.231697  [44800/60000]\n",
      "loss: 0.259845  [51200/60000]\n",
      "loss: 0.242289  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.005388 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.394431  [    0/60000]\n",
      "loss: 0.351317  [ 6400/60000]\n",
      "loss: 0.479699  [12800/60000]\n",
      "loss: 0.332809  [19200/60000]\n",
      "loss: 0.228696  [25600/60000]\n",
      "loss: 0.247483  [32000/60000]\n",
      "loss: 0.347471  [38400/60000]\n",
      "loss: 0.229632  [44800/60000]\n",
      "loss: 0.256740  [51200/60000]\n",
      "loss: 0.234644  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.005336 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.390483  [    0/60000]\n",
      "loss: 0.347747  [ 6400/60000]\n",
      "loss: 0.476271  [12800/60000]\n",
      "loss: 0.326897  [19200/60000]\n",
      "loss: 0.224856  [25600/60000]\n",
      "loss: 0.241645  [32000/60000]\n",
      "loss: 0.341195  [38400/60000]\n",
      "loss: 0.227574  [44800/60000]\n",
      "loss: 0.253690  [51200/60000]\n",
      "loss: 0.227540  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.005291 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.386930  [    0/60000]\n",
      "loss: 0.344373  [ 6400/60000]\n",
      "loss: 0.473081  [12800/60000]\n",
      "loss: 0.321472  [19200/60000]\n",
      "loss: 0.221456  [25600/60000]\n",
      "loss: 0.236534  [32000/60000]\n",
      "loss: 0.335381  [38400/60000]\n",
      "loss: 0.225462  [44800/60000]\n",
      "loss: 0.250728  [51200/60000]\n",
      "loss: 0.221023  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.005249 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.383729  [    0/60000]\n",
      "loss: 0.341122  [ 6400/60000]\n",
      "loss: 0.470097  [12800/60000]\n",
      "loss: 0.316436  [19200/60000]\n",
      "loss: 0.218376  [25600/60000]\n",
      "loss: 0.232042  [32000/60000]\n",
      "loss: 0.330008  [38400/60000]\n",
      "loss: 0.223262  [44800/60000]\n",
      "loss: 0.247865  [51200/60000]\n",
      "loss: 0.215109  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.005211 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.380841  [    0/60000]\n",
      "loss: 0.337942  [ 6400/60000]\n",
      "loss: 0.467292  [12800/60000]\n",
      "loss: 0.311700  [19200/60000]\n",
      "loss: 0.215523  [25600/60000]\n",
      "loss: 0.228076  [32000/60000]\n",
      "loss: 0.325040  [38400/60000]\n",
      "loss: 0.220962  [44800/60000]\n",
      "loss: 0.245099  [51200/60000]\n",
      "loss: 0.209792  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.005176 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.378229  [    0/60000]\n",
      "loss: 0.334797  [ 6400/60000]\n",
      "loss: 0.464642  [12800/60000]\n",
      "loss: 0.307181  [19200/60000]\n",
      "loss: 0.212831  [25600/60000]\n",
      "loss: 0.224560  [32000/60000]\n",
      "loss: 0.320438  [38400/60000]\n",
      "loss: 0.218563  [44800/60000]\n",
      "loss: 0.242420  [51200/60000]\n",
      "loss: 0.205047  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.005144 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.375856  [    0/60000]\n",
      "loss: 0.331651  [ 6400/60000]\n",
      "loss: 0.462127  [12800/60000]\n",
      "loss: 0.302805  [19200/60000]\n",
      "loss: 0.210258  [25600/60000]\n",
      "loss: 0.221430  [32000/60000]\n",
      "loss: 0.316158  [38400/60000]\n",
      "loss: 0.216078  [44800/60000]\n",
      "loss: 0.239808  [51200/60000]\n",
      "loss: 0.200837  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.005114 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.373688  [    0/60000]\n",
      "loss: 0.328475  [ 6400/60000]\n",
      "loss: 0.459729  [12800/60000]\n",
      "loss: 0.298514  [19200/60000]\n",
      "loss: 0.207778  [25600/60000]\n",
      "loss: 0.218634  [32000/60000]\n",
      "loss: 0.312155  [38400/60000]\n",
      "loss: 0.213526  [44800/60000]\n",
      "loss: 0.237248  [51200/60000]\n",
      "loss: 0.197111  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.005087 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.371693  [    0/60000]\n",
      "loss: 0.325248  [ 6400/60000]\n",
      "loss: 0.457433  [12800/60000]\n",
      "loss: 0.294265  [19200/60000]\n",
      "loss: 0.205378  [25600/60000]\n",
      "loss: 0.216128  [32000/60000]\n",
      "loss: 0.308390  [38400/60000]\n",
      "loss: 0.210924  [44800/60000]\n",
      "loss: 0.234724  [51200/60000]\n",
      "loss: 0.193816  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.005061 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.369833  [    0/60000]\n",
      "loss: 0.321951  [ 6400/60000]\n",
      "loss: 0.455223  [12800/60000]\n",
      "loss: 0.290032  [19200/60000]\n",
      "loss: 0.203050  [25600/60000]\n",
      "loss: 0.213871  [32000/60000]\n",
      "loss: 0.304825  [38400/60000]\n",
      "loss: 0.208285  [44800/60000]\n",
      "loss: 0.232224  [51200/60000]\n",
      "loss: 0.190891  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.005037 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.368073  [    0/60000]\n",
      "loss: 0.318578  [ 6400/60000]\n",
      "loss: 0.453085  [12800/60000]\n",
      "loss: 0.285801  [19200/60000]\n",
      "loss: 0.200791  [25600/60000]\n",
      "loss: 0.211825  [32000/60000]\n",
      "loss: 0.301430  [38400/60000]\n",
      "loss: 0.205613  [44800/60000]\n",
      "loss: 0.229738  [51200/60000]\n",
      "loss: 0.188280  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.005015 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.366368  [    0/60000]\n",
      "loss: 0.315130  [ 6400/60000]\n",
      "loss: 0.451004  [12800/60000]\n",
      "loss: 0.281569  [19200/60000]\n",
      "loss: 0.198601  [25600/60000]\n",
      "loss: 0.209957  [32000/60000]\n",
      "loss: 0.298179  [38400/60000]\n",
      "loss: 0.202905  [44800/60000]\n",
      "loss: 0.227260  [51200/60000]\n",
      "loss: 0.185928  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.004995 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.364673  [    0/60000]\n",
      "loss: 0.311616  [ 6400/60000]\n",
      "loss: 0.448961  [12800/60000]\n",
      "loss: 0.277338  [19200/60000]\n",
      "loss: 0.196484  [25600/60000]\n",
      "loss: 0.208234  [32000/60000]\n",
      "loss: 0.295056  [38400/60000]\n",
      "loss: 0.200157  [44800/60000]\n",
      "loss: 0.224787  [51200/60000]\n",
      "loss: 0.183791  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.004976 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.362942  [    0/60000]\n",
      "loss: 0.308052  [ 6400/60000]\n",
      "loss: 0.446940  [12800/60000]\n",
      "loss: 0.273116  [19200/60000]\n",
      "loss: 0.194444  [25600/60000]\n",
      "loss: 0.206626  [32000/60000]\n",
      "loss: 0.292047  [38400/60000]\n",
      "loss: 0.197370  [44800/60000]\n",
      "loss: 0.222316  [51200/60000]\n",
      "loss: 0.181828  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.004958 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.361133  [    0/60000]\n",
      "loss: 0.304456  [ 6400/60000]\n",
      "loss: 0.444925  [12800/60000]\n",
      "loss: 0.268912  [19200/60000]\n",
      "loss: 0.192486  [25600/60000]\n",
      "loss: 0.205107  [32000/60000]\n",
      "loss: 0.289140  [38400/60000]\n",
      "loss: 0.194549  [44800/60000]\n",
      "loss: 0.219848  [51200/60000]\n",
      "loss: 0.180008  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.004942 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.359209  [    0/60000]\n",
      "loss: 0.300849  [ 6400/60000]\n",
      "loss: 0.442901  [12800/60000]\n",
      "loss: 0.264738  [19200/60000]\n",
      "loss: 0.190616  [25600/60000]\n",
      "loss: 0.203654  [32000/60000]\n",
      "loss: 0.286330  [38400/60000]\n",
      "loss: 0.191702  [44800/60000]\n",
      "loss: 0.217384  [51200/60000]\n",
      "loss: 0.178304  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.004927 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.357144  [    0/60000]\n",
      "loss: 0.297249  [ 6400/60000]\n",
      "loss: 0.440859  [12800/60000]\n",
      "loss: 0.260603  [19200/60000]\n",
      "loss: 0.188838  [25600/60000]\n",
      "loss: 0.202245  [32000/60000]\n",
      "loss: 0.283615  [38400/60000]\n",
      "loss: 0.188842  [44800/60000]\n",
      "loss: 0.214925  [51200/60000]\n",
      "loss: 0.176694  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.004913 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.354916  [    0/60000]\n",
      "loss: 0.293674  [ 6400/60000]\n",
      "loss: 0.438794  [12800/60000]\n",
      "loss: 0.256518  [19200/60000]\n",
      "loss: 0.187154  [25600/60000]\n",
      "loss: 0.200863  [32000/60000]\n",
      "loss: 0.280996  [38400/60000]\n",
      "loss: 0.185982  [44800/60000]\n",
      "loss: 0.212469  [51200/60000]\n",
      "loss: 0.175161  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.004900 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.352518  [    0/60000]\n",
      "loss: 0.290141  [ 6400/60000]\n",
      "loss: 0.436702  [12800/60000]\n",
      "loss: 0.252491  [19200/60000]\n",
      "loss: 0.185566  [25600/60000]\n",
      "loss: 0.199492  [32000/60000]\n",
      "loss: 0.278476  [38400/60000]\n",
      "loss: 0.183132  [44800/60000]\n",
      "loss: 0.210018  [51200/60000]\n",
      "loss: 0.173688  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.004889 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.349947  [    0/60000]\n",
      "loss: 0.286663  [ 6400/60000]\n",
      "loss: 0.434584  [12800/60000]\n",
      "loss: 0.248529  [19200/60000]\n",
      "loss: 0.184073  [25600/60000]\n",
      "loss: 0.198119  [32000/60000]\n",
      "loss: 0.276056  [38400/60000]\n",
      "loss: 0.180304  [44800/60000]\n",
      "loss: 0.207571  [51200/60000]\n",
      "loss: 0.172264  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.004878 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.347211  [    0/60000]\n",
      "loss: 0.283253  [ 6400/60000]\n",
      "loss: 0.432443  [12800/60000]\n",
      "loss: 0.244639  [19200/60000]\n",
      "loss: 0.182673  [25600/60000]\n",
      "loss: 0.196734  [32000/60000]\n",
      "loss: 0.273740  [38400/60000]\n",
      "loss: 0.177506  [44800/60000]\n",
      "loss: 0.205126  [51200/60000]\n",
      "loss: 0.170877  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.004868 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.344321  [    0/60000]\n",
      "loss: 0.279919  [ 6400/60000]\n",
      "loss: 0.430282  [12800/60000]\n",
      "loss: 0.240825  [19200/60000]\n",
      "loss: 0.181363  [25600/60000]\n",
      "loss: 0.195332  [32000/60000]\n",
      "loss: 0.271526  [38400/60000]\n",
      "loss: 0.174746  [44800/60000]\n",
      "loss: 0.202684  [51200/60000]\n",
      "loss: 0.169519  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.004859 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.341295  [    0/60000]\n",
      "loss: 0.276668  [ 6400/60000]\n",
      "loss: 0.428105  [12800/60000]\n",
      "loss: 0.237089  [19200/60000]\n",
      "loss: 0.180137  [25600/60000]\n",
      "loss: 0.193907  [32000/60000]\n",
      "loss: 0.269412  [38400/60000]\n",
      "loss: 0.172031  [44800/60000]\n",
      "loss: 0.200243  [51200/60000]\n",
      "loss: 0.168180  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.004851 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.338153  [    0/60000]\n",
      "loss: 0.273504  [ 6400/60000]\n",
      "loss: 0.425915  [12800/60000]\n",
      "loss: 0.233433  [19200/60000]\n",
      "loss: 0.178989  [25600/60000]\n",
      "loss: 0.192457  [32000/60000]\n",
      "loss: 0.267394  [38400/60000]\n",
      "loss: 0.169365  [44800/60000]\n",
      "loss: 0.197805  [51200/60000]\n",
      "loss: 0.166854  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.004844 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.334917  [    0/60000]\n",
      "loss: 0.270427  [ 6400/60000]\n",
      "loss: 0.423715  [12800/60000]\n",
      "loss: 0.229858  [19200/60000]\n",
      "loss: 0.177914  [25600/60000]\n",
      "loss: 0.190981  [32000/60000]\n",
      "loss: 0.265466  [38400/60000]\n",
      "loss: 0.166754  [44800/60000]\n",
      "loss: 0.195372  [51200/60000]\n",
      "loss: 0.165534  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.004838 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.331605  [    0/60000]\n",
      "loss: 0.267437  [ 6400/60000]\n",
      "loss: 0.421505  [12800/60000]\n",
      "loss: 0.226362  [19200/60000]\n",
      "loss: 0.176903  [25600/60000]\n",
      "loss: 0.189478  [32000/60000]\n",
      "loss: 0.263620  [38400/60000]\n",
      "loss: 0.164198  [44800/60000]\n",
      "loss: 0.192947  [51200/60000]\n",
      "loss: 0.164213  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.004833 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.328235  [    0/60000]\n",
      "loss: 0.264533  [ 6400/60000]\n",
      "loss: 0.419286  [12800/60000]\n",
      "loss: 0.222945  [19200/60000]\n",
      "loss: 0.175950  [25600/60000]\n",
      "loss: 0.187949  [32000/60000]\n",
      "loss: 0.261850  [38400/60000]\n",
      "loss: 0.161700  [44800/60000]\n",
      "loss: 0.190535  [51200/60000]\n",
      "loss: 0.162886  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.004828 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.324822  [    0/60000]\n",
      "loss: 0.261710  [ 6400/60000]\n",
      "loss: 0.417055  [12800/60000]\n",
      "loss: 0.219604  [19200/60000]\n",
      "loss: 0.175047  [25600/60000]\n",
      "loss: 0.186393  [32000/60000]\n",
      "loss: 0.260149  [38400/60000]\n",
      "loss: 0.159258  [44800/60000]\n",
      "loss: 0.188140  [51200/60000]\n",
      "loss: 0.161546  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.004824 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.321378  [    0/60000]\n",
      "loss: 0.258964  [ 6400/60000]\n",
      "loss: 0.414812  [12800/60000]\n",
      "loss: 0.216335  [19200/60000]\n",
      "loss: 0.174189  [25600/60000]\n",
      "loss: 0.184812  [32000/60000]\n",
      "loss: 0.258509  [38400/60000]\n",
      "loss: 0.156869  [44800/60000]\n",
      "loss: 0.185768  [51200/60000]\n",
      "loss: 0.160191  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.004822 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.317911  [    0/60000]\n",
      "loss: 0.256292  [ 6400/60000]\n",
      "loss: 0.412555  [12800/60000]\n",
      "loss: 0.213133  [19200/60000]\n",
      "loss: 0.173368  [25600/60000]\n",
      "loss: 0.183205  [32000/60000]\n",
      "loss: 0.256924  [38400/60000]\n",
      "loss: 0.154530  [44800/60000]\n",
      "loss: 0.183424  [51200/60000]\n",
      "loss: 0.158817  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004819 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.314430  [    0/60000]\n",
      "loss: 0.253689  [ 6400/60000]\n",
      "loss: 0.410281  [12800/60000]\n",
      "loss: 0.209993  [19200/60000]\n",
      "loss: 0.172579  [25600/60000]\n",
      "loss: 0.181574  [32000/60000]\n",
      "loss: 0.255388  [38400/60000]\n",
      "loss: 0.152238  [44800/60000]\n",
      "loss: 0.181114  [51200/60000]\n",
      "loss: 0.157425  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004818 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.310938  [    0/60000]\n",
      "loss: 0.251151  [ 6400/60000]\n",
      "loss: 0.407990  [12800/60000]\n",
      "loss: 0.206909  [19200/60000]\n",
      "loss: 0.171818  [25600/60000]\n",
      "loss: 0.179920  [32000/60000]\n",
      "loss: 0.253895  [38400/60000]\n",
      "loss: 0.149988  [44800/60000]\n",
      "loss: 0.178839  [51200/60000]\n",
      "loss: 0.156014  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004817 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.307440  [    0/60000]\n",
      "loss: 0.248673  [ 6400/60000]\n",
      "loss: 0.405680  [12800/60000]\n",
      "loss: 0.203875  [19200/60000]\n",
      "loss: 0.171080  [25600/60000]\n",
      "loss: 0.178243  [32000/60000]\n",
      "loss: 0.252440  [38400/60000]\n",
      "loss: 0.147776  [44800/60000]\n",
      "loss: 0.176603  [51200/60000]\n",
      "loss: 0.154588  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004817 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.303939  [    0/60000]\n",
      "loss: 0.246249  [ 6400/60000]\n",
      "loss: 0.403351  [12800/60000]\n",
      "loss: 0.200888  [19200/60000]\n",
      "loss: 0.170362  [25600/60000]\n",
      "loss: 0.176546  [32000/60000]\n",
      "loss: 0.251018  [38400/60000]\n",
      "loss: 0.145601  [44800/60000]\n",
      "loss: 0.174407  [51200/60000]\n",
      "loss: 0.153151  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004818 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.300438  [    0/60000]\n",
      "loss: 0.243872  [ 6400/60000]\n",
      "loss: 0.401002  [12800/60000]\n",
      "loss: 0.197942  [19200/60000]\n",
      "loss: 0.169661  [25600/60000]\n",
      "loss: 0.174829  [32000/60000]\n",
      "loss: 0.249623  [38400/60000]\n",
      "loss: 0.143459  [44800/60000]\n",
      "loss: 0.172252  [51200/60000]\n",
      "loss: 0.151707  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004819 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.296939  [    0/60000]\n",
      "loss: 0.241533  [ 6400/60000]\n",
      "loss: 0.398631  [12800/60000]\n",
      "loss: 0.195035  [19200/60000]\n",
      "loss: 0.168977  [25600/60000]\n",
      "loss: 0.173095  [32000/60000]\n",
      "loss: 0.248251  [38400/60000]\n",
      "loss: 0.141350  [44800/60000]\n",
      "loss: 0.170136  [51200/60000]\n",
      "loss: 0.150261  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004821 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.293443  [    0/60000]\n",
      "loss: 0.239222  [ 6400/60000]\n",
      "loss: 0.396235  [12800/60000]\n",
      "loss: 0.192167  [19200/60000]\n",
      "loss: 0.168307  [25600/60000]\n",
      "loss: 0.171345  [32000/60000]\n",
      "loss: 0.246899  [38400/60000]\n",
      "loss: 0.139273  [44800/60000]\n",
      "loss: 0.168058  [51200/60000]\n",
      "loss: 0.148817  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004824 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.289954  [    0/60000]\n",
      "loss: 0.236933  [ 6400/60000]\n",
      "loss: 0.393808  [12800/60000]\n",
      "loss: 0.189337  [19200/60000]\n",
      "loss: 0.167651  [25600/60000]\n",
      "loss: 0.169582  [32000/60000]\n",
      "loss: 0.245562  [38400/60000]\n",
      "loss: 0.137226  [44800/60000]\n",
      "loss: 0.166015  [51200/60000]\n",
      "loss: 0.147380  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004827 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.286473  [    0/60000]\n",
      "loss: 0.234664  [ 6400/60000]\n",
      "loss: 0.391346  [12800/60000]\n",
      "loss: 0.186549  [19200/60000]\n",
      "loss: 0.167010  [25600/60000]\n",
      "loss: 0.167809  [32000/60000]\n",
      "loss: 0.244239  [38400/60000]\n",
      "loss: 0.135209  [44800/60000]\n",
      "loss: 0.164006  [51200/60000]\n",
      "loss: 0.145952  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.004831 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.283003  [    0/60000]\n",
      "loss: 0.232413  [ 6400/60000]\n",
      "loss: 0.388843  [12800/60000]\n",
      "loss: 0.183808  [19200/60000]\n",
      "loss: 0.166380  [25600/60000]\n",
      "loss: 0.166028  [32000/60000]\n",
      "loss: 0.242926  [38400/60000]\n",
      "loss: 0.133223  [44800/60000]\n",
      "loss: 0.162027  [51200/60000]\n",
      "loss: 0.144538  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004835 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.279546  [    0/60000]\n",
      "loss: 0.230180  [ 6400/60000]\n",
      "loss: 0.386291  [12800/60000]\n",
      "loss: 0.181118  [19200/60000]\n",
      "loss: 0.165761  [25600/60000]\n",
      "loss: 0.164240  [32000/60000]\n",
      "loss: 0.241621  [38400/60000]\n",
      "loss: 0.131267  [44800/60000]\n",
      "loss: 0.160075  [51200/60000]\n",
      "loss: 0.143138  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004840 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.276105  [    0/60000]\n",
      "loss: 0.227968  [ 6400/60000]\n",
      "loss: 0.383687  [12800/60000]\n",
      "loss: 0.178483  [19200/60000]\n",
      "loss: 0.165150  [25600/60000]\n",
      "loss: 0.162449  [32000/60000]\n",
      "loss: 0.240322  [38400/60000]\n",
      "loss: 0.129342  [44800/60000]\n",
      "loss: 0.158150  [51200/60000]\n",
      "loss: 0.141753  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004845 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.272685  [    0/60000]\n",
      "loss: 0.225778  [ 6400/60000]\n",
      "loss: 0.381025  [12800/60000]\n",
      "loss: 0.175910  [19200/60000]\n",
      "loss: 0.164547  [25600/60000]\n",
      "loss: 0.160657  [32000/60000]\n",
      "loss: 0.239025  [38400/60000]\n",
      "loss: 0.127447  [44800/60000]\n",
      "loss: 0.156247  [51200/60000]\n",
      "loss: 0.140384  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004851 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.269287  [    0/60000]\n",
      "loss: 0.223610  [ 6400/60000]\n",
      "loss: 0.378302  [12800/60000]\n",
      "loss: 0.173401  [19200/60000]\n",
      "loss: 0.163948  [25600/60000]\n",
      "loss: 0.158864  [32000/60000]\n",
      "loss: 0.237729  [38400/60000]\n",
      "loss: 0.125582  [44800/60000]\n",
      "loss: 0.154366  [51200/60000]\n",
      "loss: 0.139029  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004857 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.265916  [    0/60000]\n",
      "loss: 0.221466  [ 6400/60000]\n",
      "loss: 0.375517  [12800/60000]\n",
      "loss: 0.170959  [19200/60000]\n",
      "loss: 0.163353  [25600/60000]\n",
      "loss: 0.157073  [32000/60000]\n",
      "loss: 0.236431  [38400/60000]\n",
      "loss: 0.123746  [44800/60000]\n",
      "loss: 0.152504  [51200/60000]\n",
      "loss: 0.137686  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004864 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.262573  [    0/60000]\n",
      "loss: 0.219346  [ 6400/60000]\n",
      "loss: 0.372669  [12800/60000]\n",
      "loss: 0.168586  [19200/60000]\n",
      "loss: 0.162761  [25600/60000]\n",
      "loss: 0.155284  [32000/60000]\n",
      "loss: 0.235129  [38400/60000]\n",
      "loss: 0.121939  [44800/60000]\n",
      "loss: 0.150661  [51200/60000]\n",
      "loss: 0.136355  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004871 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.259262  [    0/60000]\n",
      "loss: 0.217250  [ 6400/60000]\n",
      "loss: 0.369762  [12800/60000]\n",
      "loss: 0.166282  [19200/60000]\n",
      "loss: 0.162171  [25600/60000]\n",
      "loss: 0.153498  [32000/60000]\n",
      "loss: 0.233818  [38400/60000]\n",
      "loss: 0.120159  [44800/60000]\n",
      "loss: 0.148835  [51200/60000]\n",
      "loss: 0.135034  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004879 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.255985  [    0/60000]\n",
      "loss: 0.215177  [ 6400/60000]\n",
      "loss: 0.366796  [12800/60000]\n",
      "loss: 0.164046  [19200/60000]\n",
      "loss: 0.161582  [25600/60000]\n",
      "loss: 0.151716  [32000/60000]\n",
      "loss: 0.232498  [38400/60000]\n",
      "loss: 0.118407  [44800/60000]\n",
      "loss: 0.147026  [51200/60000]\n",
      "loss: 0.133719  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004887 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.252744  [    0/60000]\n",
      "loss: 0.213128  [ 6400/60000]\n",
      "loss: 0.363777  [12800/60000]\n",
      "loss: 0.161877  [19200/60000]\n",
      "loss: 0.160994  [25600/60000]\n",
      "loss: 0.149937  [32000/60000]\n",
      "loss: 0.231162  [38400/60000]\n",
      "loss: 0.116682  [44800/60000]\n",
      "loss: 0.145235  [51200/60000]\n",
      "loss: 0.132410  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004896 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.249541  [    0/60000]\n",
      "loss: 0.211100  [ 6400/60000]\n",
      "loss: 0.360710  [12800/60000]\n",
      "loss: 0.159773  [19200/60000]\n",
      "loss: 0.160407  [25600/60000]\n",
      "loss: 0.148161  [32000/60000]\n",
      "loss: 0.229810  [38400/60000]\n",
      "loss: 0.114983  [44800/60000]\n",
      "loss: 0.143460  [51200/60000]\n",
      "loss: 0.131105  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.004905 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.246376  [    0/60000]\n",
      "loss: 0.209093  [ 6400/60000]\n",
      "loss: 0.357600  [12800/60000]\n",
      "loss: 0.157731  [19200/60000]\n",
      "loss: 0.159822  [25600/60000]\n",
      "loss: 0.146389  [32000/60000]\n",
      "loss: 0.228437  [38400/60000]\n",
      "loss: 0.113310  [44800/60000]\n",
      "loss: 0.141704  [51200/60000]\n",
      "loss: 0.129802  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.004914 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.243251  [    0/60000]\n",
      "loss: 0.207105  [ 6400/60000]\n",
      "loss: 0.354451  [12800/60000]\n",
      "loss: 0.155746  [19200/60000]\n",
      "loss: 0.159238  [25600/60000]\n",
      "loss: 0.144620  [32000/60000]\n",
      "loss: 0.227040  [38400/60000]\n",
      "loss: 0.111662  [44800/60000]\n",
      "loss: 0.139966  [51200/60000]\n",
      "loss: 0.128501  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004924 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.240165  [    0/60000]\n",
      "loss: 0.205134  [ 6400/60000]\n",
      "loss: 0.351271  [12800/60000]\n",
      "loss: 0.153815  [19200/60000]\n",
      "loss: 0.158656  [25600/60000]\n",
      "loss: 0.142854  [32000/60000]\n",
      "loss: 0.225615  [38400/60000]\n",
      "loss: 0.110039  [44800/60000]\n",
      "loss: 0.138246  [51200/60000]\n",
      "loss: 0.127200  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004935 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.237120  [    0/60000]\n",
      "loss: 0.203180  [ 6400/60000]\n",
      "loss: 0.348064  [12800/60000]\n",
      "loss: 0.151934  [19200/60000]\n",
      "loss: 0.158077  [25600/60000]\n",
      "loss: 0.141089  [32000/60000]\n",
      "loss: 0.224161  [38400/60000]\n",
      "loss: 0.108442  [44800/60000]\n",
      "loss: 0.136547  [51200/60000]\n",
      "loss: 0.125900  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.004946 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.234115  [    0/60000]\n",
      "loss: 0.201240  [ 6400/60000]\n",
      "loss: 0.344836  [12800/60000]\n",
      "loss: 0.150098  [19200/60000]\n",
      "loss: 0.157500  [25600/60000]\n",
      "loss: 0.139326  [32000/60000]\n",
      "loss: 0.222674  [38400/60000]\n",
      "loss: 0.106872  [44800/60000]\n",
      "loss: 0.134867  [51200/60000]\n",
      "loss: 0.124599  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.004958 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.231151  [    0/60000]\n",
      "loss: 0.199312  [ 6400/60000]\n",
      "loss: 0.341591  [12800/60000]\n",
      "loss: 0.148303  [19200/60000]\n",
      "loss: 0.156927  [25600/60000]\n",
      "loss: 0.137564  [32000/60000]\n",
      "loss: 0.221151  [38400/60000]\n",
      "loss: 0.105328  [44800/60000]\n",
      "loss: 0.133208  [51200/60000]\n",
      "loss: 0.123298  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.004970 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.228227  [    0/60000]\n",
      "loss: 0.197396  [ 6400/60000]\n",
      "loss: 0.338334  [12800/60000]\n",
      "loss: 0.146544  [19200/60000]\n",
      "loss: 0.156357  [25600/60000]\n",
      "loss: 0.135803  [32000/60000]\n",
      "loss: 0.219592  [38400/60000]\n",
      "loss: 0.103812  [44800/60000]\n",
      "loss: 0.131570  [51200/60000]\n",
      "loss: 0.121997  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.004982 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.225343  [    0/60000]\n",
      "loss: 0.195488  [ 6400/60000]\n",
      "loss: 0.335068  [12800/60000]\n",
      "loss: 0.144817  [19200/60000]\n",
      "loss: 0.155790  [25600/60000]\n",
      "loss: 0.134042  [32000/60000]\n",
      "loss: 0.217993  [38400/60000]\n",
      "loss: 0.102326  [44800/60000]\n",
      "loss: 0.129953  [51200/60000]\n",
      "loss: 0.120697  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.004995 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.222498  [    0/60000]\n",
      "loss: 0.193589  [ 6400/60000]\n",
      "loss: 0.331797  [12800/60000]\n",
      "loss: 0.143118  [19200/60000]\n",
      "loss: 0.155228  [25600/60000]\n",
      "loss: 0.132282  [32000/60000]\n",
      "loss: 0.216354  [38400/60000]\n",
      "loss: 0.100870  [44800/60000]\n",
      "loss: 0.128356  [51200/60000]\n",
      "loss: 0.119397  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005009 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.219692  [    0/60000]\n",
      "loss: 0.191696  [ 6400/60000]\n",
      "loss: 0.328523  [12800/60000]\n",
      "loss: 0.141443  [19200/60000]\n",
      "loss: 0.154669  [25600/60000]\n",
      "loss: 0.130522  [32000/60000]\n",
      "loss: 0.214672  [38400/60000]\n",
      "loss: 0.099447  [44800/60000]\n",
      "loss: 0.126780  [51200/60000]\n",
      "loss: 0.118098  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005023 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.216925  [    0/60000]\n",
      "loss: 0.189809  [ 6400/60000]\n",
      "loss: 0.325250  [12800/60000]\n",
      "loss: 0.139788  [19200/60000]\n",
      "loss: 0.154114  [25600/60000]\n",
      "loss: 0.128763  [32000/60000]\n",
      "loss: 0.212946  [38400/60000]\n",
      "loss: 0.098056  [44800/60000]\n",
      "loss: 0.125225  [51200/60000]\n",
      "loss: 0.116802  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005038 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.214194  [    0/60000]\n",
      "loss: 0.187927  [ 6400/60000]\n",
      "loss: 0.321978  [12800/60000]\n",
      "loss: 0.138150  [19200/60000]\n",
      "loss: 0.153562  [25600/60000]\n",
      "loss: 0.127006  [32000/60000]\n",
      "loss: 0.211176  [38400/60000]\n",
      "loss: 0.096698  [44800/60000]\n",
      "loss: 0.123689  [51200/60000]\n",
      "loss: 0.115507  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005053 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.211499  [    0/60000]\n",
      "loss: 0.186050  [ 6400/60000]\n",
      "loss: 0.318710  [12800/60000]\n",
      "loss: 0.136524  [19200/60000]\n",
      "loss: 0.153015  [25600/60000]\n",
      "loss: 0.125250  [32000/60000]\n",
      "loss: 0.209360  [38400/60000]\n",
      "loss: 0.095374  [44800/60000]\n",
      "loss: 0.122172  [51200/60000]\n",
      "loss: 0.114215  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005068 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.208837  [    0/60000]\n",
      "loss: 0.184177  [ 6400/60000]\n",
      "loss: 0.315447  [12800/60000]\n",
      "loss: 0.134907  [19200/60000]\n",
      "loss: 0.152471  [25600/60000]\n",
      "loss: 0.123497  [32000/60000]\n",
      "loss: 0.207497  [38400/60000]\n",
      "loss: 0.094083  [44800/60000]\n",
      "loss: 0.120674  [51200/60000]\n",
      "loss: 0.112926  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005085 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.206209  [    0/60000]\n",
      "loss: 0.182311  [ 6400/60000]\n",
      "loss: 0.312192  [12800/60000]\n",
      "loss: 0.133297  [19200/60000]\n",
      "loss: 0.151930  [25600/60000]\n",
      "loss: 0.121748  [32000/60000]\n",
      "loss: 0.205587  [38400/60000]\n",
      "loss: 0.092825  [44800/60000]\n",
      "loss: 0.119193  [51200/60000]\n",
      "loss: 0.111641  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005101 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.203611  [    0/60000]\n",
      "loss: 0.180451  [ 6400/60000]\n",
      "loss: 0.308946  [12800/60000]\n",
      "loss: 0.131689  [19200/60000]\n",
      "loss: 0.151393  [25600/60000]\n",
      "loss: 0.120003  [32000/60000]\n",
      "loss: 0.203629  [38400/60000]\n",
      "loss: 0.091598  [44800/60000]\n",
      "loss: 0.117728  [51200/60000]\n",
      "loss: 0.110360  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005118 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.201042  [    0/60000]\n",
      "loss: 0.178598  [ 6400/60000]\n",
      "loss: 0.305710  [12800/60000]\n",
      "loss: 0.130082  [19200/60000]\n",
      "loss: 0.150858  [25600/60000]\n",
      "loss: 0.118264  [32000/60000]\n",
      "loss: 0.201621  [38400/60000]\n",
      "loss: 0.090404  [44800/60000]\n",
      "loss: 0.116278  [51200/60000]\n",
      "loss: 0.109083  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005136 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.198502  [    0/60000]\n",
      "loss: 0.176753  [ 6400/60000]\n",
      "loss: 0.302487  [12800/60000]\n",
      "loss: 0.128473  [19200/60000]\n",
      "loss: 0.150326  [25600/60000]\n",
      "loss: 0.116533  [32000/60000]\n",
      "loss: 0.199564  [38400/60000]\n",
      "loss: 0.089239  [44800/60000]\n",
      "loss: 0.114843  [51200/60000]\n",
      "loss: 0.107812  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005154 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.195987  [    0/60000]\n",
      "loss: 0.174917  [ 6400/60000]\n",
      "loss: 0.299278  [12800/60000]\n",
      "loss: 0.126860  [19200/60000]\n",
      "loss: 0.149797  [25600/60000]\n",
      "loss: 0.114811  [32000/60000]\n",
      "loss: 0.197458  [38400/60000]\n",
      "loss: 0.088104  [44800/60000]\n",
      "loss: 0.113419  [51200/60000]\n",
      "loss: 0.106548  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005173 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.193498  [    0/60000]\n",
      "loss: 0.173091  [ 6400/60000]\n",
      "loss: 0.296086  [12800/60000]\n",
      "loss: 0.125241  [19200/60000]\n",
      "loss: 0.149270  [25600/60000]\n",
      "loss: 0.113099  [32000/60000]\n",
      "loss: 0.195302  [38400/60000]\n",
      "loss: 0.086999  [44800/60000]\n",
      "loss: 0.112007  [51200/60000]\n",
      "loss: 0.105290  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005192 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.191033  [    0/60000]\n",
      "loss: 0.171275  [ 6400/60000]\n",
      "loss: 0.292910  [12800/60000]\n",
      "loss: 0.123616  [19200/60000]\n",
      "loss: 0.148743  [25600/60000]\n",
      "loss: 0.111399  [32000/60000]\n",
      "loss: 0.193096  [38400/60000]\n",
      "loss: 0.085921  [44800/60000]\n",
      "loss: 0.110605  [51200/60000]\n",
      "loss: 0.104039  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005211 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.188592  [    0/60000]\n",
      "loss: 0.169472  [ 6400/60000]\n",
      "loss: 0.289755  [12800/60000]\n",
      "loss: 0.121982  [19200/60000]\n",
      "loss: 0.148217  [25600/60000]\n",
      "loss: 0.109711  [32000/60000]\n",
      "loss: 0.190840  [38400/60000]\n",
      "loss: 0.084871  [44800/60000]\n",
      "loss: 0.109211  [51200/60000]\n",
      "loss: 0.102797  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005231 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.186175  [    0/60000]\n",
      "loss: 0.167680  [ 6400/60000]\n",
      "loss: 0.286621  [12800/60000]\n",
      "loss: 0.120340  [19200/60000]\n",
      "loss: 0.147691  [25600/60000]\n",
      "loss: 0.108038  [32000/60000]\n",
      "loss: 0.188535  [38400/60000]\n",
      "loss: 0.083847  [44800/60000]\n",
      "loss: 0.107825  [51200/60000]\n",
      "loss: 0.101562  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005251 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.183782  [    0/60000]\n",
      "loss: 0.165900  [ 6400/60000]\n",
      "loss: 0.283513  [12800/60000]\n",
      "loss: 0.118689  [19200/60000]\n",
      "loss: 0.147164  [25600/60000]\n",
      "loss: 0.106380  [32000/60000]\n",
      "loss: 0.186181  [38400/60000]\n",
      "loss: 0.082850  [44800/60000]\n",
      "loss: 0.106445  [51200/60000]\n",
      "loss: 0.100336  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005272 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.181413  [    0/60000]\n",
      "loss: 0.164134  [ 6400/60000]\n",
      "loss: 0.280430  [12800/60000]\n",
      "loss: 0.117028  [19200/60000]\n",
      "loss: 0.146634  [25600/60000]\n",
      "loss: 0.104738  [32000/60000]\n",
      "loss: 0.183779  [38400/60000]\n",
      "loss: 0.081878  [44800/60000]\n",
      "loss: 0.105070  [51200/60000]\n",
      "loss: 0.099118  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005293 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.179069  [    0/60000]\n",
      "loss: 0.162381  [ 6400/60000]\n",
      "loss: 0.277378  [12800/60000]\n",
      "loss: 0.115358  [19200/60000]\n",
      "loss: 0.146100  [25600/60000]\n",
      "loss: 0.103112  [32000/60000]\n",
      "loss: 0.181330  [38400/60000]\n",
      "loss: 0.080932  [44800/60000]\n",
      "loss: 0.103700  [51200/60000]\n",
      "loss: 0.097908  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005315 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.176751  [    0/60000]\n",
      "loss: 0.160642  [ 6400/60000]\n",
      "loss: 0.274357  [12800/60000]\n",
      "loss: 0.113680  [19200/60000]\n",
      "loss: 0.145562  [25600/60000]\n",
      "loss: 0.101504  [32000/60000]\n",
      "loss: 0.178836  [38400/60000]\n",
      "loss: 0.080010  [44800/60000]\n",
      "loss: 0.102335  [51200/60000]\n",
      "loss: 0.096707  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005337 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.174457  [    0/60000]\n",
      "loss: 0.158917  [ 6400/60000]\n",
      "loss: 0.271372  [12800/60000]\n",
      "loss: 0.111995  [19200/60000]\n",
      "loss: 0.145018  [25600/60000]\n",
      "loss: 0.099912  [32000/60000]\n",
      "loss: 0.176298  [38400/60000]\n",
      "loss: 0.079112  [44800/60000]\n",
      "loss: 0.100974  [51200/60000]\n",
      "loss: 0.095515  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005359 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.172191  [    0/60000]\n",
      "loss: 0.157205  [ 6400/60000]\n",
      "loss: 0.268424  [12800/60000]\n",
      "loss: 0.110303  [19200/60000]\n",
      "loss: 0.144466  [25600/60000]\n",
      "loss: 0.098338  [32000/60000]\n",
      "loss: 0.173719  [38400/60000]\n",
      "loss: 0.078236  [44800/60000]\n",
      "loss: 0.099618  [51200/60000]\n",
      "loss: 0.094331  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005382 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.169951  [    0/60000]\n",
      "loss: 0.155509  [ 6400/60000]\n",
      "loss: 0.265516  [12800/60000]\n",
      "loss: 0.108607  [19200/60000]\n",
      "loss: 0.143906  [25600/60000]\n",
      "loss: 0.096781  [32000/60000]\n",
      "loss: 0.171103  [38400/60000]\n",
      "loss: 0.077379  [44800/60000]\n",
      "loss: 0.098268  [51200/60000]\n",
      "loss: 0.093155  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005404 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.167737  [    0/60000]\n",
      "loss: 0.153828  [ 6400/60000]\n",
      "loss: 0.262649  [12800/60000]\n",
      "loss: 0.106908  [19200/60000]\n",
      "loss: 0.143337  [25600/60000]\n",
      "loss: 0.095242  [32000/60000]\n",
      "loss: 0.168450  [38400/60000]\n",
      "loss: 0.076541  [44800/60000]\n",
      "loss: 0.096925  [51200/60000]\n",
      "loss: 0.091987  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005428 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.165552  [    0/60000]\n",
      "loss: 0.152162  [ 6400/60000]\n",
      "loss: 0.259827  [12800/60000]\n",
      "loss: 0.105209  [19200/60000]\n",
      "loss: 0.142758  [25600/60000]\n",
      "loss: 0.093720  [32000/60000]\n",
      "loss: 0.165765  [38400/60000]\n",
      "loss: 0.075717  [44800/60000]\n",
      "loss: 0.095591  [51200/60000]\n",
      "loss: 0.090826  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005451 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.163393  [    0/60000]\n",
      "loss: 0.150513  [ 6400/60000]\n",
      "loss: 0.257051  [12800/60000]\n",
      "loss: 0.103512  [19200/60000]\n",
      "loss: 0.142167  [25600/60000]\n",
      "loss: 0.092216  [32000/60000]\n",
      "loss: 0.163051  [38400/60000]\n",
      "loss: 0.074906  [44800/60000]\n",
      "loss: 0.094268  [51200/60000]\n",
      "loss: 0.089672  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005475 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.161261  [    0/60000]\n",
      "loss: 0.148879  [ 6400/60000]\n",
      "loss: 0.254322  [12800/60000]\n",
      "loss: 0.101820  [19200/60000]\n",
      "loss: 0.141564  [25600/60000]\n",
      "loss: 0.090729  [32000/60000]\n",
      "loss: 0.160311  [38400/60000]\n",
      "loss: 0.074104  [44800/60000]\n",
      "loss: 0.092957  [51200/60000]\n",
      "loss: 0.088525  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005499 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.159156  [    0/60000]\n",
      "loss: 0.147261  [ 6400/60000]\n",
      "loss: 0.251641  [12800/60000]\n",
      "loss: 0.100136  [19200/60000]\n",
      "loss: 0.140950  [25600/60000]\n",
      "loss: 0.089258  [32000/60000]\n",
      "loss: 0.157549  [38400/60000]\n",
      "loss: 0.073309  [44800/60000]\n",
      "loss: 0.091659  [51200/60000]\n",
      "loss: 0.087384  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005523 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.157077  [    0/60000]\n",
      "loss: 0.145659  [ 6400/60000]\n",
      "loss: 0.249010  [12800/60000]\n",
      "loss: 0.098461  [19200/60000]\n",
      "loss: 0.140321  [25600/60000]\n",
      "loss: 0.087805  [32000/60000]\n",
      "loss: 0.154769  [38400/60000]\n",
      "loss: 0.072519  [44800/60000]\n",
      "loss: 0.090375  [51200/60000]\n",
      "loss: 0.086249  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005547 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.155024  [    0/60000]\n",
      "loss: 0.144072  [ 6400/60000]\n",
      "loss: 0.246429  [12800/60000]\n",
      "loss: 0.096799  [19200/60000]\n",
      "loss: 0.139680  [25600/60000]\n",
      "loss: 0.086366  [32000/60000]\n",
      "loss: 0.151975  [38400/60000]\n",
      "loss: 0.071733  [44800/60000]\n",
      "loss: 0.089106  [51200/60000]\n",
      "loss: 0.085119  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005572 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.152996  [    0/60000]\n",
      "loss: 0.142498  [ 6400/60000]\n",
      "loss: 0.243898  [12800/60000]\n",
      "loss: 0.095151  [19200/60000]\n",
      "loss: 0.139024  [25600/60000]\n",
      "loss: 0.084943  [32000/60000]\n",
      "loss: 0.149172  [38400/60000]\n",
      "loss: 0.070950  [44800/60000]\n",
      "loss: 0.087852  [51200/60000]\n",
      "loss: 0.083994  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.005596 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T13:02:37.177355Z",
     "iopub.status.busy": "2021-03-16T13:02:37.174635Z",
     "iopub.status.idle": "2021-03-16T13:02:37.388255Z",
     "shell.execute_reply": "2021-03-16T13:02:37.387510Z"
    },
    "papermill": {
     "duration": 0.558468,
     "end_time": "2021-03-16T13:02:37.388447",
     "exception": false,
     "start_time": "2021-03-16T13:02:36.829979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "x_axes = list(range(epochs))\n",
    "\n",
    "ax.set(xlabel=\"Epochs\",\n",
    "       ylabel=\"Accuracy\",\n",
    "       title=\"Accuracy plot\")\n",
    "\n",
    "ax.plot(x_axes, train_logs, color=\"green\", label=\"Train\")\n",
    "ax.plot(x_axes, test_logs, color=\"red\", label=\"Test\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 366.892795,
   "end_time": "2021-03-16T13:02:38.534039",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-16T12:56:31.641244",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
